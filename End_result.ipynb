{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a113ce24-0180-4fb9-81fe-732355fcecf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Started MCP event loop\n",
      "INFO:langchain_mcp_tools.langchain_mcp_tools:MCP server \"local_http\": initializing with: {'url': 'http://127.0.0.1:8000/mcp'}\n",
      "INFO:langchain_mcp_tools.langchain_mcp_tools:MCP server \"local_http\": Pre-validating authentication\n",
      "ERROR:langchain_mcp_tools.langchain_mcp_tools:MCP server \"local_http\": error during initialization: MCP server \"local_http\": Connection failed: All connection attempts failed\n",
      "ERROR:__main__:‚ùå Could not load MCP tools: MCP server \"local_http\": Connection failed: All connection attempts failed\n",
      "INFO:__main__:Continuing without MCP tools...\n",
      "INFO:__main__:‚úÖ Loaded 2 tools\n",
      "INFO:__main__:‚úÖ Created agent: Python Coder\n",
      "INFO:__main__:‚úÖ Created agent: Data Analyst\n",
      "INFO:__main__:‚úÖ Created agent: Assistant\n",
      "INFO:__main__:‚úÖ Dashboard initialized successfully!\n",
      "/tmp/ipykernel_28259/3952706411.py:485: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Conversation\", height=600)\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7861/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7861/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://bc56fd75fbc45c603a.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://bc56fd75fbc45c603a.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://bc56fd75fbc45c603a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Started MCP event loop\n",
      "INFO:langchain_mcp_tools.langchain_mcp_tools:MCP server \"example_server\": initializing with: {'url': 'http://localhost:8000/mcp'}\n",
      "INFO:langchain_mcp_tools.langchain_mcp_tools:MCP server \"example_server\": Pre-validating authentication\n",
      "ERROR:langchain_mcp_tools.langchain_mcp_tools:MCP server \"example_server\": error during initialization: MCP server \"example_server\": Connection failed: All connection attempts failed\n",
      "ERROR:__main__:‚ùå Could not load MCP tools: MCP server \"example_server\": Connection failed: All connection attempts failed\n",
      "INFO:__main__:Continuing without MCP tools...\n",
      "INFO:__main__:‚úÖ Loaded 2 tools\n",
      "INFO:__main__:‚úÖ Created agent: Python Coder\n",
      "INFO:__main__:‚úÖ Created agent: Data Analyst\n",
      "INFO:__main__:‚úÖ Created agent: Assistant\n",
      "INFO:__main__:‚úÖ Dashboard initialized successfully!\n",
      "/tmp/ipykernel_28259/3952706411.py:485: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot = gr.Chatbot(label=\"Conversation\", height=600)\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7862/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7862/ \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/v3/tunnel-request \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on public URL: https://deb280a64f214f8036.gradio.live\n",
      "\n",
      "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: HEAD https://deb280a64f214f8036.gradio.live \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://deb280a64f214f8036.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mHello! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/transcriptions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3mI'm just a program, so I don't have feelings, but I'm here and ready to help you! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/audio/speech \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "from typing import Dict, List\n",
    "import logging\n",
    "import json\n",
    "import numpy as np\n",
    "import tempfile\n",
    "import os\n",
    "import threading\n",
    "from typing import Optional, Tuple\n",
    "import io\n",
    "from openai import OpenAI\n",
    "# Import necessary LangChain components\n",
    "from langchain_mcp_tools import convert_mcp_to_langchain_tools\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.agents import AgentExecutor, create_tool_calling_agent\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "from langchain.tools import Tool\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "from langchain_community.tools import ShellTool\n",
    "\n",
    "import wave\n",
    "import numpy as np\n",
    "import scipy.io.wavfile as wavfile\n",
    "\n",
    "\n",
    "import dotenv\n",
    "# Load environment variables from .env file\n",
    "dotenv.load_dotenv()\n",
    "\n",
    "# Apply nest_asyncio to handle async issues\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Set up logging so we can see what's happening\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "# Initialize OpenAI client (using v1+ Python library interface)\n",
    "client = OpenAI()\n",
    "\n",
    "class SimpleAudioHandler:\n",
    "    \"\"\"Handles speech-to-text and text-to-speech using OpenAI's v1 audio endpoints.\"\"\"\n",
    "    def __init__(self):\n",
    "        self.can_hear = True\n",
    "        self.can_speak = True\n",
    "\n",
    "    def listen(self, audio_data: Tuple[int, np.ndarray]) -> str:\n",
    "        \"\"\"Transcribe audio_data using OpenAI's Whisper-based endpoint.\"\"\"\n",
    "        if not self.can_hear or audio_data is None:\n",
    "            return \"\"\n",
    "\n",
    "        sample_rate, audio_array = audio_data\n",
    "        # Pack numpy array into WAV bytes\n",
    "        buf = io.BytesIO()\n",
    "        buf.name = \"audio.wav\"  # ensure correct file extension for OpenAI\n",
    "        with wave.open(buf, 'wb') as wav_file:\n",
    "            wav_file.setnchannels(1)\n",
    "            wav_file.setsampwidth(2)\n",
    "            wav_file.setframerate(sample_rate)\n",
    "            if audio_array.dtype != np.int16:\n",
    "                audio_array = (audio_array * 32767).astype(np.int16)\n",
    "            wav_file.writeframes(audio_array.tobytes())\n",
    "        buf.seek(0)\n",
    "\n",
    "        # Call new v1 API\n",
    "        response = client.audio.transcriptions.create(\n",
    "            file=buf,\n",
    "            model=\"gpt-4o-transcribe\"\n",
    "        )\n",
    "        return getattr(response, 'text', '')\n",
    "\n",
    "    def speak(self, text: str) -> Optional[Tuple[int, np.ndarray]]:\n",
    "        \"\"\"Generate speech audio from text via OpenAI's TTS endpoint.\"\"\"\n",
    "        if not self.can_speak or not text:\n",
    "            return None\n",
    "\n",
    "        # Synthesize speech using v1 API\n",
    "        response = client.audio.speech.create(\n",
    "            model=\"gpt-4o-mini-tts\",\n",
    "            input=text,\n",
    "            voice=\"ash\"\n",
    "        )\n",
    "        audio_bytes = response\n",
    "        if not audio_bytes:\n",
    "            return None\n",
    "     # Extract raw bytes\n",
    "        if hasattr(response, 'content'):\n",
    "            audio_bytes = response.content  # typical for HTTPX-like response\n",
    "        elif hasattr(response, 'read'):\n",
    "            audio_bytes = response.read()   # fallback if streaming\n",
    "        else:\n",
    "            # assume it's already bytes\n",
    "            audio_bytes = response  # type: ignore\n",
    "\n",
    "        # Ensure bytes-like\n",
    "        if not isinstance(audio_bytes, (bytes, bytearray)):\n",
    "            try:\n",
    "                audio_bytes = bytes(audio_bytes)\n",
    "            except Exception:\n",
    "                raise TypeError(f\"Could not convert TTS response to bytes: {type(audio_bytes)}\")\n",
    "\n",
    "        # Load WAV bytes into numpy\n",
    "        tmp = tempfile.NamedTemporaryFile(delete=False, suffix=\".mp3\")\n",
    "        tmp.write(audio_bytes)\n",
    "        tmp.close()\n",
    "        # Return filepath for Gradio Audio (type=\"filepath\")\n",
    "        return tmp.name\n",
    "\n",
    "\n",
    "class SimpleMultiAgentDashboard:\n",
    "    \"\"\"A simplified multi-agent dashboard for students to learn from\"\"\"\n",
    "    \n",
    "    def __init__(self, mcp_servers: Dict, agent_configs: List[Dict]):\n",
    "        \"\"\"Initialize the dashboard with servers and agent configurations\"\"\"\n",
    "        self.mcp_servers = mcp_servers\n",
    "        self.agent_configs = agent_configs\n",
    "        self.agents = {}  # Will store our created agents\n",
    "        self.tools = []   # Will store all available tools\n",
    "        self.max_iterations = 5  # How many times an agent can use tools\n",
    "        self.audio = SimpleAudioHandler()  # For voice input/output\n",
    "        \n",
    "        # MCP event loop for async operations\n",
    "        self.mcp_loop = None\n",
    "        self.mcp_thread = None\n",
    "        self.cleanup_func = None\n",
    "        \n",
    "        # Initialize everything\n",
    "        self._setup_tools()\n",
    "        self._create_agents()\n",
    "        logger.info(\"‚úÖ Dashboard initialized successfully!\")\n",
    "        \n",
    "        # Register cleanup on exit\n",
    "        import atexit\n",
    "        atexit.register(self._cleanup)\n",
    "    \n",
    "    def _cleanup(self):\n",
    "        \"\"\"Clean up resources when shutting down\"\"\"\n",
    "        logger.info(\"Cleaning up...\")\n",
    "        \n",
    "        # Clean up MCP resources\n",
    "        if self.cleanup_func and self.mcp_loop:\n",
    "            try:\n",
    "                future = asyncio.run_coroutine_threadsafe(\n",
    "                    self.cleanup_func(),\n",
    "                    self.mcp_loop\n",
    "                )\n",
    "                future.result(timeout=5)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Cleanup error: {e}\")\n",
    "        \n",
    "        # Stop MCP event loop\n",
    "        if self.mcp_loop:\n",
    "            self.mcp_loop.call_soon_threadsafe(self.mcp_loop.stop)\n",
    "            if self.mcp_thread:\n",
    "                self.mcp_thread.join(timeout=2)\n",
    "    \n",
    "    def _setup_tools(self):\n",
    "        \"\"\"Set up all the tools our agents can use\"\"\"\n",
    "        \n",
    "        # 1. Python REPL Tool - for running Python code\n",
    "        python_tool = PythonREPLTool()\n",
    "        # Wrap it to handle different input formats\n",
    "        wrapped_python = Tool(\n",
    "            name=\"python_repl\",\n",
    "            description=\"Execute Python code. Returns the output.\",\n",
    "            func=lambda code: python_tool.run(code if isinstance(code, str) else str(code))\n",
    "        )\n",
    "        self.tools.append(wrapped_python)\n",
    "        \n",
    "        # 2. Bash/Shell Tool - for running system commands\n",
    "        bash_tool = Tool(\n",
    "            name=\"bash_command\",\n",
    "            description=\"Execute shell commands.\",\n",
    "            func=ShellTool().run\n",
    "        )\n",
    "        self.tools.append(bash_tool)\n",
    "        \n",
    "        # 3. MCP Tools - if configured\n",
    "        if self.mcp_servers:\n",
    "            self._load_mcp_tools()\n",
    "        \n",
    "        logger.info(f\"‚úÖ Loaded {len(self.tools)} tools\")\n",
    "    \n",
    "    def _load_mcp_tools(self):\n",
    "        \"\"\"Load MCP (Model Context Protocol) tools\"\"\"\n",
    "        try:\n",
    "            # Create a dedicated event loop for MCP operations\n",
    "            self.mcp_loop = asyncio.new_event_loop()\n",
    "            \n",
    "            # Run the loop in a separate thread\n",
    "            self.mcp_thread = threading.Thread(\n",
    "                target=self.mcp_loop.run_forever,\n",
    "                daemon=True,\n",
    "                name=\"MCP-Thread\"\n",
    "            )\n",
    "            self.mcp_thread.start()\n",
    "            logger.info(\"Started MCP event loop\")\n",
    "            \n",
    "            # Load MCP tools in the dedicated loop\n",
    "            future = asyncio.run_coroutine_threadsafe(\n",
    "                convert_mcp_to_langchain_tools(self.mcp_servers),\n",
    "                self.mcp_loop\n",
    "            )\n",
    "            \n",
    "            # Get the tools and cleanup function\n",
    "            mcp_tools, self.cleanup_func = future.result(timeout=30)\n",
    "            \n",
    "            # Wrap each MCP tool to work with our system\n",
    "            for tool in mcp_tools:\n",
    "                wrapped_tool = self._wrap_mcp_tool(tool)\n",
    "                self.tools.append(wrapped_tool)\n",
    "                logger.info(f\"  - Added MCP tool: {tool.name}\")\n",
    "            \n",
    "            logger.info(f\"‚úÖ Loaded {len(mcp_tools)} MCP tools\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Could not load MCP tools: {e}\")\n",
    "            logger.info(\"Continuing without MCP tools...\")\n",
    "    \n",
    "    def _wrap_mcp_tool(self, mcp_tool):\n",
    "        \"\"\"Wrap an MCP tool to handle async operations properly\"\"\"\n",
    "        def sync_wrapper(input_data):\n",
    "            \"\"\"Run the async MCP tool synchronously\"\"\"\n",
    "            try:\n",
    "                # Handle different input formats\n",
    "                if isinstance(input_data, dict):\n",
    "                    final_input = input_data\n",
    "                else:\n",
    "                    # Try to create a dict with common parameter names\n",
    "                    final_input = {\"text\": str(input_data)}\n",
    "                \n",
    "                logger.info(f\"Calling MCP tool '{mcp_tool.name}' with: {final_input}\")\n",
    "                \n",
    "                # Run the async tool in the MCP event loop\n",
    "                future = asyncio.run_coroutine_threadsafe(\n",
    "                    mcp_tool.ainvoke(final_input),\n",
    "                    self.mcp_loop\n",
    "                )\n",
    "                \n",
    "                # Wait for result\n",
    "                result = future.result(timeout=30)\n",
    "                \n",
    "                # Format the result\n",
    "                if isinstance(result, dict):\n",
    "                    return json.dumps(result, indent=2)\n",
    "                else:\n",
    "                    return str(result)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.error(f\"MCP tool error: {e}\")\n",
    "                return f\"Error using tool: {str(e)}\"\n",
    "        \n",
    "        # Create a new Tool with the wrapper\n",
    "        return Tool(\n",
    "            name=mcp_tool.name,\n",
    "            description=mcp_tool.description,\n",
    "            func=sync_wrapper\n",
    "        )\n",
    "    \n",
    "    def _create_agents(self):\n",
    "        \"\"\"Create an agent for each configuration\"\"\"\n",
    "        for config in self.agent_configs:\n",
    "            agent_name = config[\"name\"]\n",
    "            \n",
    "            # Create the language model\n",
    "            llm = ChatOpenAI(\n",
    "                model=config.get(\"model\", \"gpt-4o\"),\n",
    "                temperature=config.get(\"temperature\", 0.7)\n",
    "            )\n",
    "            \n",
    "            # Select which tools this agent can use\n",
    "            if agent_name == \"Python Coder\":\n",
    "                # Only give code execution tools\n",
    "                agent_tools = [t for t in self.tools if t.name in [\"python_repl\", \"bash_command\"]]\n",
    "            elif agent_name == \"Data Analyst\":\n",
    "                # Give all tools\n",
    "                agent_tools = self.tools\n",
    "            else:\n",
    "                # Give everything except code execution\n",
    "                agent_tools = [t for t in self.tools if t.name not in [\"python_repl\", \"bash_command\"]]\n",
    "            \n",
    "            # Create the agent's instructions\n",
    "            system_message = self._create_system_message(agent_name, agent_tools)\n",
    "            \n",
    "            # Create the prompt template\n",
    "            prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", system_message),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "                MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "            ])\n",
    "            \n",
    "            # Create the agent\n",
    "            agent = create_tool_calling_agent(llm, agent_tools, prompt)\n",
    "            \n",
    "            # Create the executor (handles tool execution)\n",
    "            executor = AgentExecutor(\n",
    "                agent=agent,\n",
    "                tools=agent_tools,\n",
    "                verbose=True,  # Show what the agent is doing\n",
    "                max_iterations=self.max_iterations\n",
    "            )\n",
    "            \n",
    "            # Store the agent\n",
    "            self.agents[agent_name] = {\n",
    "                \"executor\": executor,\n",
    "                \"tools\": agent_tools,\n",
    "                \"config\": config\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"‚úÖ Created agent: {agent_name}\")\n",
    "    \n",
    "    def _create_system_message(self, agent_name: str, tools: List) -> str:\n",
    "        \"\"\"Create instructions for each agent type\"\"\"\n",
    "        # List all available tools\n",
    "        tool_list = \"\\n\".join([f\"- {tool.name}: {tool.description}\" for tool in tools])\n",
    "        \n",
    "        if agent_name == \"Python Coder\":\n",
    "            return f\"\"\"You are a Python programming assistant.\n",
    "\n",
    "Available tools:\n",
    "{tool_list}\n",
    "\n",
    "Instructions:\n",
    "- Write clean Python code\n",
    "- Use python_repl to execute code and show results\n",
    "- Always use print() to display outputs\n",
    "- Use bash_command for system operations\"\"\"\n",
    "        \n",
    "        elif agent_name == \"Data Analyst\":\n",
    "            return f\"\"\"You are a data analysis assistant.\n",
    "\n",
    "Available tools:\n",
    "{tool_list}\n",
    "\n",
    "Instructions:\n",
    "- Use python_repl for data analysis and visualization\n",
    "- Always print() results, dataframes, and statistics\n",
    "- Use appropriate tools for different tasks\n",
    "- Explain your findings clearly\"\"\"\n",
    "        \n",
    "        else:\n",
    "            return f\"\"\"You are a helpful assistant.\n",
    "\n",
    "Available tools:\n",
    "{tool_list}\n",
    "\n",
    "Instructions:\n",
    "- Use tools to help answer questions\n",
    "- Provide clear and helpful responses\n",
    "- Explain what you're doing\"\"\"\n",
    "    \n",
    "    def chat_with_agent(self, message: str, agent_name: str, history: List) -> str:\n",
    "        \"\"\"Send a message to an agent and get a response\"\"\"\n",
    "        if agent_name not in self.agents:\n",
    "            return f\"Sorry, I don't know an agent named {agent_name}\"\n",
    "        \n",
    "        try:\n",
    "            # Get the agent's executor\n",
    "            executor = self.agents[agent_name][\"executor\"]\n",
    "            \n",
    "            # Convert history to LangChain format\n",
    "            chat_history = []\n",
    "            for msg in history[-10:]:  # Only use last 10 messages\n",
    "                if msg[\"role\"] == \"user\":\n",
    "                    chat_history.append(HumanMessage(content=msg[\"content\"]))\n",
    "                else:\n",
    "                    chat_history.append(AIMessage(content=msg[\"content\"]))\n",
    "            \n",
    "            # Get the response\n",
    "            result = executor.invoke({\n",
    "                \"input\": message,\n",
    "                \"chat_history\": chat_history\n",
    "            })\n",
    "            \n",
    "            # Return the agent's response\n",
    "            return result[\"output\"]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error: {e}\")\n",
    "            return f\"Sorry, I encountered an error: {str(e)}\"\n",
    "    \n",
    "    def process_voice_or_text(self, audio_input, text_input, agent_name, history, speak_response):\n",
    "        \"\"\"Process either voice or text input and optionally speak the response\"\"\"\n",
    "        # Get the message from voice or text\n",
    "        if audio_input is not None:\n",
    "            message = self.audio.listen(audio_input)\n",
    "            if not message:\n",
    "                return None, history, \"\", \"Could not understand audio\"\n",
    "        else:\n",
    "            message = text_input\n",
    "        \n",
    "        if not message.strip():\n",
    "            return None, history, \"\", \"No message detected\"\n",
    "        \n",
    "        # Get response from agent\n",
    "        response = self.chat_with_agent(message, agent_name, history)\n",
    "        \n",
    "        # Generate voice response if requested\n",
    "        voice_response = None\n",
    "        if speak_response and self.audio.can_speak and len(response) < 1000:\n",
    "            voice_response = self.audio.speak(response[:500])  # Limit length for TTS\n",
    "        \n",
    "        # Update history\n",
    "        new_history = history + [\n",
    "            {\"role\": \"user\", \"content\": message},\n",
    "            {\"role\": \"assistant\", \"content\": response}\n",
    "        ]\n",
    "        \n",
    "        return voice_response, new_history, \"\", message\n",
    "    \n",
    "    def create_gradio_interface(self):\n",
    "        \"\"\"Create the Gradio web interface\"\"\"\n",
    "        with gr.Blocks(title=\"Multi-Agent Assistant\", theme=gr.themes.Soft()) as interface:\n",
    "            # Title\n",
    "            gr.Markdown(\"# ü§ñ Multi-Agent Voice Assistant with Tools\")\n",
    "            gr.Markdown(\"Chat with different AI agents using voice or text!\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                # Left column - Controls\n",
    "                with gr.Column(scale=1):\n",
    "                    # Agent selector\n",
    "                    agent_dropdown = gr.Dropdown(\n",
    "                        choices=[config[\"name\"] for config in self.agent_configs],\n",
    "                        value=self.agent_configs[0][\"name\"],\n",
    "                        label=\"Select Agent\"\n",
    "                    )\n",
    "                    \n",
    "                    # Max iterations slider\n",
    "                    iterations_slider = gr.Slider(\n",
    "                        minimum=1,\n",
    "                        maximum=10,\n",
    "                        value=self.max_iterations,\n",
    "                        step=1,\n",
    "                        label=\"Max Tool Uses\",\n",
    "                        info=\"How many times the agent can use tools\"\n",
    "                    )\n",
    "                    \n",
    "                    # Agent info display\n",
    "                    agent_info = gr.Markdown(\"\")\n",
    "                    \n",
    "                    # Voice input (if available)\n",
    "                    if self.audio.can_hear:\n",
    "                        audio_input = gr.Audio(\n",
    "                            sources=[\"microphone\"],\n",
    "                            type=\"numpy\",\n",
    "                            label=\"üé§ Voice Input (click to record)\"\n",
    "                        )\n",
    "                    else:\n",
    "                        audio_input = None\n",
    "                        gr.Markdown(\"*Voice input not available - install SpeechRecognition*\")\n",
    "                    \n",
    "                    # Text input\n",
    "                    text_input = gr.Textbox(\n",
    "                        label=\"Text Input\",\n",
    "                        placeholder=\"Or type your message here...\",\n",
    "                        lines=3\n",
    "                    )\n",
    "                    \n",
    "                    # Send button\n",
    "                    send_button = gr.Button(\"Send\", variant=\"primary\")\n",
    "                    \n",
    "                    # Voice output toggle (if available)\n",
    "                    if self.audio.can_speak:\n",
    "                        speak_toggle = gr.Checkbox(\n",
    "                            label=\"üîä Speak Response\",\n",
    "                            value=True\n",
    "                        )\n",
    "                        audio_output = gr.Audio(\n",
    "                            label=\"Voice Response\",\n",
    "                            type=\"numpy\",\n",
    "                            autoplay=True\n",
    "                        )\n",
    "                    else:\n",
    "                        speak_toggle = gr.State(False)\n",
    "                        audio_output = None\n",
    "                        gr.Markdown(\"*Voice output not available - install edge-tts*\")\n",
    "                \n",
    "                # Right column - Chat\n",
    "                with gr.Column(scale=2):\n",
    "                    # Chat history display\n",
    "                    chatbot = gr.Chatbot(label=\"Conversation\", height=600)\n",
    "                    \n",
    "                    # Last input display\n",
    "                    last_input = gr.Textbox(label=\"Last Input\", interactive=False)\n",
    "                    \n",
    "                    # Clear button\n",
    "                    clear_button = gr.Button(\"Clear Chat\")\n",
    "            \n",
    "            # Hidden state to store conversation history\n",
    "            history_state = gr.State([])\n",
    "            \n",
    "            # Function to update agent info\n",
    "            def update_agent_info(agent_name):\n",
    "                \"\"\"Show information about the selected agent\"\"\"\n",
    "                if agent_name in self.agents:\n",
    "                    tools = self.agents[agent_name][\"tools\"]\n",
    "                    tool_names = [tool.name for tool in tools]\n",
    "                    return f\"**{agent_name}**\\n\\nAvailable tools: {', '.join(tool_names)}\"\n",
    "                return \"\"\n",
    "            \n",
    "            # Function to update max iterations\n",
    "            def update_iterations(value):\n",
    "                \"\"\"Update the max iterations for all agents\"\"\"\n",
    "                self.max_iterations = value\n",
    "                for agent_data in self.agents.values():\n",
    "                    agent_data[\"executor\"].max_iterations = value\n",
    "            \n",
    "            # Function to clear chat\n",
    "            def clear_chat():\n",
    "                \"\"\"Clear the conversation\"\"\"\n",
    "                return [], [], \"\", \"\"\n",
    "            \n",
    "            # Connect all the interface elements\n",
    "            \n",
    "            # Update agent info when selection changes\n",
    "            agent_dropdown.change(\n",
    "                update_agent_info,\n",
    "                inputs=[agent_dropdown],\n",
    "                outputs=[agent_info]\n",
    "            )\n",
    "            \n",
    "            # Update iterations when slider changes\n",
    "            iterations_slider.change(\n",
    "                update_iterations,\n",
    "                inputs=[iterations_slider]\n",
    "            )\n",
    "            \n",
    "            # Process message when send button clicked\n",
    "            send_button.click(\n",
    "                self.process_voice_or_text,\n",
    "                inputs=[\n",
    "                    audio_input if audio_input else gr.State(None),\n",
    "                    text_input,\n",
    "                    agent_dropdown,\n",
    "                    history_state,\n",
    "                    speak_toggle\n",
    "                ],\n",
    "                outputs=[\n",
    "                    audio_output if audio_output else gr.State(None),\n",
    "                    history_state,\n",
    "                    text_input,\n",
    "                    last_input\n",
    "                ]\n",
    "            )\n",
    "            \n",
    "            # Update chat display when history changes\n",
    "            history_state.change(\n",
    "                lambda h: [(m[\"content\"], None) if m[\"role\"] == \"user\" \n",
    "                          else (None, m[\"content\"]) for m in h],\n",
    "                inputs=[history_state],\n",
    "                outputs=[chatbot]\n",
    "            )\n",
    "            \n",
    "            # Clear everything when clear button clicked\n",
    "            clear_button.click(\n",
    "                clear_chat,\n",
    "                outputs=[chatbot, history_state, text_input, last_input]\n",
    "            )\n",
    "            \n",
    "            # Initialize agent info on load\n",
    "            interface.load(\n",
    "                lambda: update_agent_info(self.agent_configs[0][\"name\"]),\n",
    "                outputs=[agent_info]\n",
    "            )\n",
    "        \n",
    "        return interface\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Configure MCP servers (optional)\n",
    "    MCP_SERVERS = {\n",
    "        \"local_http\": {\"url\": \"http://127.0.0.1:8000/mcp\"}\n",
    "    }\n",
    "    \n",
    "    # Configure agents\n",
    "    AGENT_CONFIGS = [\n",
    "        {\n",
    "            \"name\": \"Python Coder\",\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"description\": \"Helps with Python programming\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Data Analyst\", \n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.3,\n",
    "            \"description\": \"Helps with data analysis\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Assistant\",\n",
    "            \"model\": \"gpt-4o\", \n",
    "            \"temperature\": 0.7,\n",
    "            \"description\": \"General helpful assistant\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Create and launch the dashboard\n",
    "    dashboard = SimpleMultiAgentDashboard(MCP_SERVERS, AGENT_CONFIGS)\n",
    "    app = dashboard.create_gradio_interface()\n",
    "    app.launch(share=True)\n",
    "    \"\"\"A simplified multi-agent dashboard for students to learn from\"\"\"\n",
    "    \n",
    "    def __init__(self, mcp_servers: Dict, agent_configs: List[Dict]):\n",
    "        \"\"\"Initialize the dashboard with servers and agent configurations\"\"\"\n",
    "        self.mcp_servers = mcp_servers\n",
    "        self.agent_configs = agent_configs\n",
    "        self.agents = {}  # Will store our created agents\n",
    "        self.tools = []   # Will store all available tools\n",
    "        self.max_iterations = 5  # How many times an agent can use tools\n",
    "        \n",
    "        # Initialize everything\n",
    "        self._setup_tools()\n",
    "        self._create_agents()\n",
    "        logger.info(\"‚úÖ Dashboard initialized successfully!\")\n",
    "    \n",
    "    def _setup_tools(self):\n",
    "        \"\"\"Set up all the tools our agents can use\"\"\"\n",
    "        \n",
    "        # 1. Python REPL Tool - for running Python code\n",
    "        python_tool = PythonREPLTool()\n",
    "        # Wrap it to handle different input formats\n",
    "        wrapped_python = Tool(\n",
    "            name=\"python_repl\",\n",
    "            description=\"Execute Python code. Returns the output.\",\n",
    "            func=lambda code: python_tool.run(code if isinstance(code, str) else str(code))\n",
    "        )\n",
    "        self.tools.append(wrapped_python)\n",
    "        \n",
    "        # 2. Bash/Shell Tool - for running system commands\n",
    "        bash_tool = Tool(\n",
    "            name=\"bash_command\",\n",
    "            description=\"Execute shell commands.\",\n",
    "            func=ShellTool().run\n",
    "        )\n",
    "        self.tools.append(bash_tool)\n",
    "        \n",
    "        # 3. MCP Tools - if configured\n",
    "        if self.mcp_servers:\n",
    "            self._load_mcp_tools()\n",
    "        \n",
    "        logger.info(f\"‚úÖ Loaded {len(self.tools)} tools\")\n",
    "    \n",
    "    def _load_mcp_tools(self):\n",
    "        \"\"\"Load MCP (Model Context Protocol) tools\"\"\"\n",
    "        try:\n",
    "            # Create an event loop for async operations\n",
    "            loop = asyncio.new_event_loop()\n",
    "            asyncio.set_event_loop(loop)\n",
    "            \n",
    "            # Load MCP tools\n",
    "            mcp_tools, cleanup = loop.run_until_complete(\n",
    "                convert_mcp_to_langchain_tools(self.mcp_servers)\n",
    "            )\n",
    "            \n",
    "            # Add each MCP tool to our tools list\n",
    "            for tool in mcp_tools:\n",
    "                self.tools.append(tool)\n",
    "                logger.info(f\"  - Added MCP tool: {tool.name}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"‚ùå Could not load MCP tools: {e}\")\n",
    "            logger.info(\"Continuing without MCP tools...\")\n",
    "    \n",
    "    def _create_agents(self):\n",
    "        \"\"\"Create an agent for each configuration\"\"\"\n",
    "        for config in self.agent_configs:\n",
    "            agent_name = config[\"name\"]\n",
    "            \n",
    "            # Create the language model\n",
    "            llm = ChatOpenAI(\n",
    "                model=config.get(\"model\", \"gpt-4o\"),\n",
    "                temperature=config.get(\"temperature\", 0.7)\n",
    "            )\n",
    "            \n",
    "            # Select which tools this agent can use\n",
    "            if agent_name == \"Python Coder\":\n",
    "                # Only give code execution tools\n",
    "                agent_tools = [t for t in self.tools if t.name in [\"python_repl\", \"bash_command\"]]\n",
    "            elif agent_name == \"Data Analyst\":\n",
    "                # Give all tools\n",
    "                agent_tools = self.tools\n",
    "            else:\n",
    "                # Give everything except code execution\n",
    "                agent_tools = [t for t in self.tools if t.name not in [\"python_repl\", \"bash_command\"]]\n",
    "            \n",
    "            # Create the agent's instructions\n",
    "            system_message = self._create_system_message(agent_name, agent_tools)\n",
    "            \n",
    "            # Create the prompt template\n",
    "            prompt = ChatPromptTemplate.from_messages([\n",
    "                (\"system\", system_message),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                (\"human\", \"{input}\"),\n",
    "                MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "            ])\n",
    "            \n",
    "            # Create the agent\n",
    "            agent = create_tool_calling_agent(llm, agent_tools, prompt)\n",
    "            \n",
    "            # Create the executor (handles tool execution)\n",
    "            executor = AgentExecutor(\n",
    "                agent=agent,\n",
    "                tools=agent_tools,\n",
    "                verbose=True,  # Show what the agent is doing\n",
    "                max_iterations=self.max_iterations\n",
    "            )\n",
    "            \n",
    "            # Store the agent\n",
    "            self.agents[agent_name] = {\n",
    "                \"executor\": executor,\n",
    "                \"tools\": agent_tools,\n",
    "                \"config\": config\n",
    "            }\n",
    "            \n",
    "            logger.info(f\"‚úÖ Created agent: {agent_name}\")\n",
    "    \n",
    "    def _create_system_message(self, agent_name: str, tools: List) -> str:\n",
    "        \"\"\"Create instructions for each agent type\"\"\"\n",
    "        # List all available tools\n",
    "        tool_list = \"\\n\".join([f\"- {tool.name}: {tool.description}\" for tool in tools])\n",
    "        \n",
    "        if agent_name == \"Python Coder\":\n",
    "            return f\"\"\"You are a Python programming assistant.\n",
    "\n",
    "Available tools:\n",
    "{tool_list}\n",
    "\n",
    "Instructions:\n",
    "- Write clean Python code\n",
    "- Use python_repl to execute code and show results\n",
    "- Always use print() to display outputs\n",
    "- Use bash_command for system operations\"\"\"\n",
    "        \n",
    "        elif agent_name == \"Data Analyst\":\n",
    "            return f\"\"\"You are a data analysis assistant.\n",
    "\n",
    "Available tools:\n",
    "{tool_list}\n",
    "\n",
    "Instructions:\n",
    "- Use python_repl for data analysis and visualization\n",
    "- Always print() results, dataframes, and statistics\n",
    "- Use appropriate tools for different tasks\n",
    "- Explain your findings clearly\"\"\"\n",
    "        \n",
    "        else:\n",
    "            return f\"\"\"You are a helpful assistant.\n",
    "\n",
    "Available tools:\n",
    "{tool_list}\n",
    "\n",
    "Instructions:\n",
    "- Use tools to help answer questions\n",
    "- Provide clear and helpful responses\n",
    "- Explain what you're doing\"\"\"\n",
    "    \n",
    "    def chat_with_agent(self, message: str, agent_name: str, history: List) -> str:\n",
    "        \"\"\"Send a message to an agent and get a response\"\"\"\n",
    "        if agent_name not in self.agents:\n",
    "            return f\"Sorry, I don't know an agent named {agent_name}\"\n",
    "        \n",
    "        try:\n",
    "            # Get the agent's executor\n",
    "            executor = self.agents[agent_name][\"executor\"]\n",
    "            \n",
    "            # Convert history to LangChain format\n",
    "            chat_history = []\n",
    "            for msg in history[-10:]:  # Only use last 10 messages\n",
    "                if msg[\"role\"] == \"user\":\n",
    "                    chat_history.append(HumanMessage(content=msg[\"content\"]))\n",
    "                else:\n",
    "                    chat_history.append(AIMessage(content=msg[\"content\"]))\n",
    "            \n",
    "            # Get the response\n",
    "            result = executor.invoke({\n",
    "                \"input\": message,\n",
    "                \"chat_history\": chat_history\n",
    "            })\n",
    "            \n",
    "            # Return the agent's response\n",
    "            return result[\"output\"]\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error: {e}\")\n",
    "            return f\"Sorry, I encountered an error: {str(e)}\"\n",
    "    \n",
    "    def create_gradio_interface(self):\n",
    "        \"\"\"Create the Gradio web interface\"\"\"\n",
    "        with gr.Blocks(title=\"Multi-Agent Assistant\", theme=gr.themes.Soft()) as interface:\n",
    "            # Title\n",
    "            gr.Markdown(\"# ü§ñ Multi-Agent Assistant with Tools\")\n",
    "            gr.Markdown(\"Chat with different AI agents that can use various tools!\")\n",
    "            \n",
    "            with gr.Row():\n",
    "                # Left column - Controls\n",
    "                with gr.Column(scale=1):\n",
    "                    # Agent selector\n",
    "                    agent_dropdown = gr.Dropdown(\n",
    "                        choices=[config[\"name\"] for config in self.agent_configs],\n",
    "                        value=self.agent_configs[0][\"name\"],\n",
    "                        label=\"Select Agent\"\n",
    "                    )\n",
    "                    \n",
    "                    # Max iterations slider\n",
    "                    iterations_slider = gr.Slider(\n",
    "                        minimum=1,\n",
    "                        maximum=10,\n",
    "                        value=self.max_iterations,\n",
    "                        step=1,\n",
    "                        label=\"Max Tool Uses\",\n",
    "                        info=\"How many times the agent can use tools\"\n",
    "                    )\n",
    "                    \n",
    "                    # Agent info display\n",
    "                    agent_info = gr.Markdown(\"\")\n",
    "                    \n",
    "                    # Text input\n",
    "                    text_input = gr.Textbox(\n",
    "                        label=\"Your Message\",\n",
    "                        placeholder=\"Type your message here...\",\n",
    "                        lines=3\n",
    "                    )\n",
    "                    \n",
    "                    # Send button\n",
    "                    send_button = gr.Button(\"Send\", variant=\"primary\")\n",
    "                \n",
    "                # Right column - Chat\n",
    "                with gr.Column(scale=2):\n",
    "                    # Chat history display\n",
    "                    chatbot = gr.Chatbot(label=\"Conversation\", height=600)\n",
    "                    \n",
    "                    # Last input display\n",
    "                    last_input = gr.Textbox(label=\"Last Input\", interactive=False)\n",
    "                    \n",
    "                    # Clear button\n",
    "                    clear_button = gr.Button(\"Clear Chat\")\n",
    "            \n",
    "            # Hidden state to store conversation history\n",
    "            history_state = gr.State([])\n",
    "            \n",
    "            # Function to update agent info\n",
    "            def update_agent_info(agent_name):\n",
    "                \"\"\"Show information about the selected agent\"\"\"\n",
    "                if agent_name in self.agents:\n",
    "                    tools = self.agents[agent_name][\"tools\"]\n",
    "                    tool_names = [tool.name for tool in tools]\n",
    "                    return f\"**{agent_name}**\\n\\nAvailable tools: {', '.join(tool_names)}\"\n",
    "                return \"\"\n",
    "            \n",
    "            # Function to update max iterations\n",
    "            def update_iterations(value):\n",
    "                \"\"\"Update the max iterations for all agents\"\"\"\n",
    "                self.max_iterations = value\n",
    "                for agent_data in self.agents.values():\n",
    "                    agent_data[\"executor\"].max_iterations = value\n",
    "            \n",
    "            # Function to process messages\n",
    "            def process_message(text, agent_name, history):\n",
    "                \"\"\"Process a user message and get agent response\"\"\"\n",
    "                if not text.strip():\n",
    "                    return history, \"\", \"Please enter a message\"\n",
    "                \n",
    "                # Get agent response\n",
    "                response = self.chat_with_agent(text, agent_name, history)\n",
    "                \n",
    "                # Update history\n",
    "                new_history = history + [\n",
    "                    {\"role\": \"user\", \"content\": text},\n",
    "                    {\"role\": \"assistant\", \"content\": response}\n",
    "                ]\n",
    "                \n",
    "                # Update chat display\n",
    "                chat_display = []\n",
    "                for msg in new_history:\n",
    "                    if msg[\"role\"] == \"user\":\n",
    "                        chat_display.append((msg[\"content\"], None))\n",
    "                    else:\n",
    "                        chat_display.append((None, msg[\"content\"]))\n",
    "                \n",
    "                return new_history, \"\", text\n",
    "            \n",
    "            # Function to clear chat\n",
    "            def clear_chat():\n",
    "                \"\"\"Clear the conversation\"\"\"\n",
    "                return [], [], \"\", \"\"\n",
    "            \n",
    "            # Connect all the interface elements\n",
    "            \n",
    "            # Update agent info when selection changes\n",
    "            agent_dropdown.change(\n",
    "                update_agent_info,\n",
    "                inputs=[agent_dropdown],\n",
    "                outputs=[agent_info]\n",
    "            )\n",
    "            \n",
    "            # Update iterations when slider changes\n",
    "            iterations_slider.change(\n",
    "                update_iterations,\n",
    "                inputs=[iterations_slider]\n",
    "            )\n",
    "            \n",
    "            # Process message when send button clicked\n",
    "            send_button.click(\n",
    "                process_message,\n",
    "                inputs=[text_input, agent_dropdown, history_state],\n",
    "                outputs=[history_state, text_input, last_input]\n",
    "            )\n",
    "            \n",
    "            # Update chat display when history changes\n",
    "            history_state.change(\n",
    "                lambda h: [(m[\"content\"], None) if m[\"role\"] == \"user\" \n",
    "                          else (None, m[\"content\"]) for m in h],\n",
    "                inputs=[history_state],\n",
    "                outputs=[chatbot]\n",
    "            )\n",
    "            \n",
    "            # Clear everything when clear button clicked\n",
    "            clear_button.click(\n",
    "                clear_chat,\n",
    "                outputs=[chatbot, history_state, text_input, last_input]\n",
    "            )\n",
    "            \n",
    "            # Initialize agent info on load\n",
    "            interface.load(\n",
    "                lambda: update_agent_info(self.agent_configs[0][\"name\"]),\n",
    "                outputs=[agent_info]\n",
    "            )\n",
    "        \n",
    "        return interface\n",
    "\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Configure MCP servers (optional)\n",
    "    MCP_SERVERS = {\n",
    "        \"example_server\": {\"url\": \"http://localhost:8000/mcp\"}\n",
    "    }\n",
    "    \n",
    "    # Configure agents\n",
    "    AGENT_CONFIGS = [\n",
    "        {\n",
    "            \"name\": \"Python Coder\",\n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.2,\n",
    "            \"description\": \"Helps with Python programming\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Data Analyst\", \n",
    "            \"model\": \"gpt-4o\",\n",
    "            \"temperature\": 0.3,\n",
    "            \"description\": \"Helps with data analysis\"\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Assistant\",\n",
    "            \"model\": \"gpt-4o\", \n",
    "            \"temperature\": 0.7,\n",
    "            \"description\": \"General helpful assistant\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # Create and launch the dashboard\n",
    "    dashboard = SimpleMultiAgentDashboard(MCP_SERVERS, AGENT_CONFIGS)\n",
    "    app = dashboard.create_gradio_interface()\n",
    "    app.launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4991cf-789d-452b-8351-10b445bb8a97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
